
#
# =================================================================================================
# Notebook: 03_feature_selection.ipynb
#
# Description:
# This notebook applies feature selection techniques to identify the most relevant
# features for predicting heart disease.
# =================================================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE, chi2, SelectKBest

# Load the cleaned (but not PCA-transformed) dataset
try:
    df = pd.read_csv('cleaned_heart_disease.csv')
    print("Cleaned dataset loaded successfully.")
except FileNotFoundError:
    print("Error: 'cleaned_heart_disease.csv' not found.")
    exit()

X = df.drop('target', axis=1)
y = df['target']

# =================================================================================================
# Sprint 2.3: Feature Selection
# =================================================================================================

# -------------------------------------------------------------------------------------------------
# Step 1: Use Feature Importance from Random Forest.
# -------------------------------------------------------------------------------------------------
print("\nStep 1: Calculating Feature Importance using Random Forest...")
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X, y)

importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)

# Visualize feature importance
plt.figure(figsize=(12, 8))
sns.barplot(x=importances, y=importances.index)
plt.title('Feature Importance from Random Forest')
plt.xlabel('Importance Score')
plt.ylabel('Features')
plt.show()


# -------------------------------------------------------------------------------------------------
# Step 2: Apply Recursive Feature Elimination (RFE).
# -------------------------------------------------------------------------------------------------
print("\nStep 2: Applying Recursive Feature Elimination (RFE)...")
# We'll aim for the top 10 features, but this number can be tuned.
rfe = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=10)
rfe.fit(X, y)

rfe_features = X.columns[rfe.support_]
print("Selected features via RFE:", list(rfe_features))


# -------------------------------------------------------------------------------------------------
# Step 3: Use Chi-Square Test to check feature significance.
# -------------------------------------------------------------------------------------------------
print("\nStep 3: Applying Chi-Square Test...")
# Chi-Square test requires non-negative features. Our scaled data has negative values.
# So, we'll reload the data and only apply Min-Max scaling for this test.
from sklearn.preprocessing import MinMaxScaler
X_chi = df.drop('target', axis=1)
X_chi = MinMaxScaler().fit_transform(X_chi)

chi2_selector = SelectKBest(score_func=chi2, k=10)
chi2_selector.fit(X_chi, y)

chi2_scores = pd.DataFrame({'Feature': X.columns, 'Chi2_Score': chi2_selector.scores_})
print("\nChi-Square Scores for Features:")
print(chi2_scores.sort_values(by='Chi2_Score', ascending=False))


# -------------------------------------------------------------------------------------------------
# Deliverable: Reduced dataset with selected key features
# -------------------------------------------------------------------------------------------------
print("\nSelecting final features based on Random Forest importance...")
# Based on the bar plot, we can select the top features (e.g., top 10 or 12).
# Let's select the top 12 features for our model.
final_features = importances.index[:12].tolist()
print("Final selected features:", final_features)

# Create the reduced dataset
df_reduced = df[final_features + ['target']]
df_reduced.to_csv('feature_selected_dataset.csv', index=False)
print("\nReduced dataset saved to 'feature_selected_dataset.csv'.")
print("Shape of reduced dataset:", df_reduced.shape)
